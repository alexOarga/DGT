[*] Run ID 0: seed=0, split_index=0
    Starting now: 2023-04-24 00:52:39.528099
Computing "none" node features for CustomDataset.
[*] Loaded dataset 'custom' from 'none':
  Data(x=[1884984, 10], edge_index=[2, 4408782], edge_attr=[4408782, 1], y=[1884984, 1], edge_weight=[4408782, 1], reactions_mask=[1884984])
  undirected: False
  num graphs: 660
  avg num_nodes/graph: 2856
  num node features: 10
  num edge features: 1
  num classes: 2
Precomputing Positional Encoding statistics: ['MagLapPE'] for all graphs...
  ...estimated to be undirected: False
** Using precomputed dataset.pkl
Done! Took 00:00:00.30
GraphGymModule(
  (model): GPSModel(
    (encoder): FeatureEncoder(
      (node_encoder): Concat2NodeEncoder(
        (encoder1): LinearNodeEncoder(
          (encoder): Linear(in_features=10, out_features=32, bias=True)
        )
        (encoder2): MagLapNet(
          (element_mlp): MLP(
            (0): Linear(in_features=2, out_features=4, bias=True)
            (1): Dropout(p=0.0, inplace=True)
          )
          (re_aggregate_mlp): MLP(
            (0): Linear(in_features=200, out_features=32, bias=True)
            (1): Dropout(p=0.0, inplace=True)
          )
        )
      )
      (edge_encoder): LinearEdgeEncoder(
        (encoder): Linear(in_features=1, out_features=32, bias=True)
      )
    )
    (layers): Sequential(
      (0): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (1): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (2): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (3): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (4): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (5): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (6): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
      (7): GPSLayer(
        summary: dim_h=32, local_gnn_type=CustomGatedGCN, global_model_type=Performer, heads=4
        (local_model): GatedGCNLayer()
        (local_model_2): GatedGCNLayer()
        (self_attn): SelfAttention(
          (fast_attention): FastAttention(
            (kernel_fn): ReLU()
          )
          (to_q): Linear(in_features=32, out_features=256, bias=False)
          (to_k): Linear(in_features=32, out_features=256, bias=False)
          (to_v): Linear(in_features=32, out_features=256, bias=False)
          (to_out): Linear(in_features=256, out_features=32, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (norm1_local): LayerNorm(32, affine=True, mode=graph)
        (norm1_attn): LayerNorm(32, affine=True, mode=graph)
        (dropout_local): Dropout(p=0.0, inplace=False)
        (dropout_attn): Dropout(p=0.0, inplace=False)
        (ff_linear1): Linear(in_features=32, out_features=64, bias=True)
        (ff_linear2): Linear(in_features=64, out_features=32, bias=True)
        (act_fn_ff): GELU(approximate=none)
        (norm2): LayerNorm(32, affine=True, mode=graph)
        (ff_dropout1): Dropout(p=0.0, inplace=False)
        (ff_dropout2): Dropout(p=0.0, inplace=False)
      )
    )
    (post_mp): GNNInductiveNodeHead(
      (layer_post_mp): MLP(
        (model): Sequential(
          (0): GeneralMultiLayer(
            (Layer_0): GeneralLayer(
              (layer): Linear(
                (model): Linear(32, 32, bias=True)
              )
              (post_layer): Sequential(
                (0): ReLU()
              )
            )
          )
          (1): Linear(
            (model): Linear(32, 1, bias=True)
          )
        )
      )
    )
  )
)
accelerator: cuda
benchmark: False
bn:
  eps: 1e-05
  mom: 0.1
cfg_dest: config.yaml
custom_metrics: []
dataset:
  cache_load: False
  cache_save: False
  dir: ./datasets
  edge_dim: 128
  edge_encoder: True
  edge_encoder_bn: False
  edge_encoder_name: LinearEdge
  edge_encoder_num_types: 0
  edge_message_ratio: 0.8
  edge_negative_sampling_ratio: 1.0
  edge_train_mode: all
  encoder: True
  encoder_bn: True
  encoder_dim: 128
  encoder_name: db
  format: none
  label_column: none
  label_table: none
  location: local
  name: custom
  node_encoder: True
  node_encoder_bn: False
  node_encoder_name: LinearNode+MagLapPE
  node_encoder_num_types: 0
  remove_feature: False
  resample_disjoint: False
  resample_negative: False
  shuffle: False
  shuffle_split: True
  slic_compactness: 10
  split: [0.8, 0.1, 0.1]
  split_dir: ./splits
  split_index: 0
  split_mode: standard
  task: graph
  task_type: classification
  to_undirected: False
  transductive: False
  transform: none
  tu_simple: True
devices: 1
example_arg: example
example_group:
  example_arg: example
gnn:
  act: relu
  agg: sum
  att_final_linear: False
  att_final_linear_bn: False
  att_heads: 1
  batchnorm: False
  clear_feature: True
  dim_edge: 32
  dim_inner: 32
  dropout: 0.1
  head: inductive_node
  keep_edge: 0.5
  l2norm: True
  layer_type: generalconv
  layers_mp: 2
  layers_post_mp: 2
  layers_pre_mp: 0
  msg_direction: single
  normalize_adj: False
  residual: False
  self_msg: concat
  skip_every: 1
  stage_type: stack
gpu_mem: False
gt:
  attn_dropout: 0.1
  batch_norm: False
  bigbird:
    add_cross_attention: False
    attention_type: block_sparse
    block_size: 3
    chunk_size_feed_forward: 0
    hidden_act: relu
    is_decoder: False
    layer_norm_eps: 1e-06
    max_position_embeddings: 128
    num_random_blocks: 3
    use_bias: False
  dim_hidden: 32
  dropout: 0.0
  full_graph: True
  gamma: 1e-05
  layer_norm: True
  layer_type: CustomGatedGCN+Performer
  layers: 8
  n_heads: 4
  pna_degrees: []
  residual: True
mem:
  inplace: False
metric_agg: argmax
metric_best: f1
model:
  edge_decoding: dot
  graph_pooling: mean
  loss_fun: weighted_cross_entropy
  match_upper: True
  size_average: mean
  thresh: 0.5
  type: GPSModel
name_tag: 
num_threads: 6
num_workers: 0
optim:
  base_lr: 0.001
  batch_accumulation: 1
  clip_grad_norm: True
  lr_decay: 0.1
  max_epoch: 3000
  min_lr: 0.0
  momentum: 0.9
  num_warmup_epochs: 5
  optimizer: adam
  reduce_factor: 0.1
  schedule_patience: 10
  scheduler: cosine_with_warmup
  steps: [30, 60, 90]
  weight_decay: 1e-05
out_dir: results/custom-GPS+MagLap
posenc_ElstaticSE:
  dim_pe: 16
  enable: False
  kernel:
    times: []
    times_func: range(10)
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_EquivStableLapPE:
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  raw_norm_type: none
posenc_HKdiagSE:
  dim_pe: 12
  enable: False
  kernel:
    times: []
    times_func: range(2,17)
  layers: 3
  model: Linear
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: BatchNorm
posenc_LapPE:
  dim_pe: 18
  eigen:
    eigvec_norm: L2
    laplacian_norm: none
    max_freqs: 1000
  enable: False
  layers: 2
  model: Transformer
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: none
posenc_MagLapPE:
  concatenate_eigenvalues: False
  consider_im_part: True
  d_model_aggr: 32
  d_model_elem: 2
  dim_pe: 32
  dropout_p: 0.0
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 50
  enable: True
  excl_k_eigenvectors: 1
  l2_norm: True
  layers: 3
  model: none
  n_heads: 4
  n_layers: 1
  norm: None
  norm_comps_sep: False
  num_heads: 1
  pass_as_var: False
  post_layers: 0
  q: 0.25
  q_absolute: False
  raw_norm_type: none
  return_real_output: True
  sign_rotate: True
  symmetric_norm: False
  use_attention: False
  use_gnn: False
  use_signnet: True
posenc_RWSE:
  dim_pe: 20
  enable: False
  kernel:
    times: []
    times_func: range(1,17)
  layers: 3
  model: Linear
  n_heads: 4
  pass_as_var: False
  post_layers: 0
  raw_norm_type: BatchNorm
posenc_SignNet:
  dim_pe: 16
  eigen:
    eigvec_norm: L2
    laplacian_norm: sym
    max_freqs: 10
  enable: False
  layers: 3
  model: none
  n_heads: 4
  pass_as_var: False
  phi_hidden_dim: 64
  phi_out_dim: 4
  post_layers: 0
  raw_norm_type: none
pretrained:
  dir: 
  freeze_main: False
  reset_prediction_head: True
print: both
round: 5
run_dir: results/custom-GPS+MagLap/0
run_id: 0
run_multiple_splits: []
seed: 0
share:
  dim_in: 10
  dim_out: 2
  num_splits: 3
tensorboard_agg: True
tensorboard_each_run: False
train:
  auto_resume: False
  batch_size: 2
  ckpt_best: False
  ckpt_clean: True
  ckpt_period: 100
  enable_ckpt: True
  epoch_resume: -1
  eval_period: 5
  iter_per_epoch: 32
  mode: custom
  neighbor_sizes: [20, 15, 10, 5]
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
  skip_train_eval: False
  walk_length: 4
val:
  node_per_graph: 32
  radius: extend
  sample_node: False
  sampler: full_batch
view_emb: False
wandb:
  entity: alex97almunia
  name: 
  project: gps2
  use: False
Num parameters: 391949
Start from epoch 0
